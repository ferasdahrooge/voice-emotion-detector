{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Start Off\n",
    "- This project uses a dataset found on kaggle inorder to build an accurate based on 1400 recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new directory \n",
    "! mkdir dataset\n",
    "# Download dataset from kaggle using my personal api which can be found on your kaggle account\n",
    "! KAGGLE_USERNAME=ferasdahrooge1 KAGGLE_KEY=d65a33337f60ea5b0a5ee063dd09b34d kaggle datasets download -d uwrfkaggler/ravdess-emotional-speech-audio\n",
    "# Unzip and save in newly created directory\n",
    "! unzip ravdess-emotional-speech-audio.zip -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the Dataset, Use the audio speech actors files to build a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset = \"./dataset/audio_speech_actors_01-24\"\n",
    "actor_list = os.listdir(dataset)\n",
    "path_list = []\n",
    "gender_list = []\n",
    "emotion_list = []\n",
    "\n",
    "emotion_dictionary = {\n",
    "  '01': 'neutral',\n",
    "  '02': 'calm',\n",
    "  '03': 'happy',\n",
    "  '04': 'sad',\n",
    "  '05': 'angry',\n",
    "  '06': 'fearful',\n",
    "  '07': 'disgust',\n",
    "  '08': 'surprised'\n",
    "}\n",
    "\n",
    "for directory in actor_list:\n",
    "    actor_files = os.listdir(os.path.join(dataset, directory))\n",
    "\n",
    "    for audio_file in actor_files: \n",
    "        part = audio_file.split('.')[0]\n",
    "        key = part.split('-')[2]\n",
    "        if key in emotion_dictionary:\n",
    "          gender_code = int(part.split('-')[6])\n",
    "          path_list.append(f\"{dataset}/{directory}/{audio_file}\")\n",
    "          gender_list.append('female' if gender_code % 2 == 0 else 'male')\n",
    "          emotion_list.append(emotion_dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build DataFrame\n",
    "dataframe = pd.concat([\n",
    "  pd.DataFrame(path_list, columns=[\"path\"]),\n",
    "  pd.DataFrame(gender_list, columns=[\"gender\"]),\n",
    "  pd.DataFrame(emotion_list, columns=[\"emotion\"])\n",
    "] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_16/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_16/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_16/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_16/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_16/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_08/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_08/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_08/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_08/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>./dataset/audio_speech_actors_01-24/Actor_08/0...</td>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path  gender  emotion\n",
       "0     ./dataset/audio_speech_actors_01-24/Actor_16/0...  female    angry\n",
       "1     ./dataset/audio_speech_actors_01-24/Actor_16/0...  female  fearful\n",
       "2     ./dataset/audio_speech_actors_01-24/Actor_16/0...  female  fearful\n",
       "3     ./dataset/audio_speech_actors_01-24/Actor_16/0...  female    angry\n",
       "4     ./dataset/audio_speech_actors_01-24/Actor_16/0...  female  disgust\n",
       "...                                                 ...     ...      ...\n",
       "1435  ./dataset/audio_speech_actors_01-24/Actor_08/0...  female    happy\n",
       "1436  ./dataset/audio_speech_actors_01-24/Actor_08/0...  female    happy\n",
       "1437  ./dataset/audio_speech_actors_01-24/Actor_08/0...  female     calm\n",
       "1438  ./dataset/audio_speech_actors_01-24/Actor_08/0...  female     calm\n",
       "1439  ./dataset/audio_speech_actors_01-24/Actor_08/0...  female  neutral\n",
       "\n",
       "[1440 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d8559e58fad08f6b149f9f678acd42e602cfd8cee785110be98faa6bcb4ac45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
